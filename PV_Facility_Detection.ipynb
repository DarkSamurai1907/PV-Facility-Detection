{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd1123f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-08T04:22:10.529058Z",
          "start_time": "2023-10-08T04:22:06.949817Z"
        },
        "id": "fdd1123f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "\n",
        "class MSPBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(MSPBlock, self).__init__()\n",
        "\n",
        "        # Pooling layers\n",
        "        self.pool1 = torch.nn.AdaptiveAvgPool2d((32, 32))\n",
        "        self.pool2 = torch.nn.AdaptiveAvgPool2d((16, 16))\n",
        "        self.pool3 = torch.nn.AdaptiveAvgPool2d((8, 8))\n",
        "        self.pool4 = torch.nn.AdaptiveAvgPool2d((4, 4))\n",
        "\n",
        "        # 1x1 convolution layers\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels // 16, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels, out_channels // 8, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels, out_channels // 4, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels, out_channels // 2, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        # Up-sampling layers with corrected scale factors\n",
        "        self.up1 = torch.nn.Upsample(scale_factor=(1, 1), mode='bilinear')\n",
        "        self.up2 = torch.nn.Upsample(scale_factor=(2, 2), mode='bilinear')\n",
        "        self.up3 = torch.nn.Upsample(scale_factor=(4, 4), mode='bilinear')\n",
        "        self.up4 = torch.nn.Upsample(scale_factor=(8, 8), mode='bilinear')\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pooling\n",
        "        pool1 = self.pool1(x)\n",
        "        pool2 = self.pool2(x)\n",
        "        pool3 = self.pool3(x)\n",
        "        pool4 = self.pool4(x)\n",
        "\n",
        "        # 1x1 convolution\n",
        "        conv1 = self.conv1(pool1)\n",
        "        conv2 = self.conv2(pool2)\n",
        "        conv3 = self.conv3(pool3)\n",
        "        conv4 = self.conv4(pool4)\n",
        "\n",
        "        # Up-sampling\n",
        "        up1 = self.up1(conv1)\n",
        "        up2 = self.up2(conv2)\n",
        "        up3 = self.up3(conv3)\n",
        "        up4 = self.up4(conv4)\n",
        "\n",
        "        # Concatenate\n",
        "        output = torch.cat([x, up1, up2, up3, up4], dim=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class MSDPath(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MSDPath, self).__init__()\n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.encoder.append(nn.Conv3d(1, 32, kernel_size=5, stride=1, padding=2))\n",
        "\n",
        "        self.encoder.append(nn.Sequential(\n",
        "            (nn.MaxPool3d(kernel_size=(2,2,1), stride=2)),\n",
        "            (nn.Conv3d(32, 64, kernel_size=5, stride=1, padding=2))))\n",
        "\n",
        "        self.encoder.append(nn.Sequential(\n",
        "            (nn.MaxPool3d(kernel_size=(2,2,1), stride=2)),\n",
        "            (nn.Conv3d(64, 128, kernel_size=5, stride=1, padding=2))))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(320, 16, kernel_size=1, stride=1)\n",
        "        self.conv4 = nn.Conv2d(320, 32, kernel_size=1, stride=1)\n",
        "        self.conv6 = nn.Conv2d(384, 64, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        x = x.reshape(3, 1, 256, 256, 10)\n",
        "        conv1 = self.encoder[0](x)\n",
        "\n",
        "        conv3 = self.encoder[1](conv1)\n",
        "        conv5 = self.encoder[2](conv3)\n",
        "\n",
        "\n",
        "        r1 = conv1.view((3, 320, 256, 256))\n",
        "        r2 = conv3.view((3, 320, 128, 128))\n",
        "        r3 = conv5.view((3, 384, 64, 64))\n",
        "\n",
        "        r1 = self.conv2(r1)\n",
        "        r2 = self.conv4(r2)\n",
        "        r3 = self.conv6(r3)\n",
        "\n",
        "        skips.append(r3)\n",
        "        skips.append(r2)\n",
        "        skips.append(r1)\n",
        "\n",
        "        print(\"Skips shape\")\n",
        "        for i in skips:\n",
        "            print(i.shape)\n",
        "\n",
        "        return skips\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self, in_channels=10, out_channels=1, features=[64, 128, 256]):\n",
        "        super(UNET, self).__init__()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=1, stride=2)\n",
        "\n",
        "        # Down part\n",
        "\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # UP part\n",
        "\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(nn.ConvTranspose2d(\n",
        "                feature * 2, feature, kernel_size=2, stride=2\n",
        "            ))\n",
        "            self.ups.append(DoubleConv(feature * 2, feature))\n",
        "\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(features[-1], features[-1], kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            MSPBlock(features[-1], features[-1]),\n",
        "            nn.Conv2d(sum(features)//2+features[-1]+16, features[-1]*2, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        )\n",
        "        # self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for index in range(0, len(self.ups), 2):\n",
        "            x = self.ups[index](x)\n",
        "            skip_connection = skip_connections[index // 2]\n",
        "\n",
        "            # Resize x to match the shape of skip_connection\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[index + 1](concat_skip)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "\n",
        "# def test():\n",
        "#     x = torch.randn((1, 10, 256, 256))\n",
        "#     model = UNET(in_channels=10, out_channels=1)\n",
        "#     preds = model(x)\n",
        "#     print()\n",
        "#     print(\"The final shapes\")\n",
        "#     print(x.shape)\n",
        "#     print(preds.shape)\n",
        "#     assert preds.shape == x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEj2EMbqA3Sd",
        "outputId": "1c554711-a942-4497-cd9c-12a7e6fcf2b8"
      },
      "id": "mEj2EMbqA3Sd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.3.9)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d8c980",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-08T04:22:10.559001Z",
          "start_time": "2023-10-08T04:22:10.532057Z"
        },
        "id": "c6d8c980"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import rasterio\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from skimage.transform import resize\n",
        "\n",
        "class PVDetectionDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None, output_size=(256, 256)):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.output_size = output_size\n",
        "        self.transform = transform\n",
        "        self.image_files = os.listdir(image_dir)\n",
        "        self.mask_files = os.listdir(mask_dir)\n",
        "\n",
        "        # Check if the number of image files and mask files match\n",
        "        # assert len(self.image_files) == len(self.mask_files), \"Number of images and masks must match.\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
        "\n",
        "        with rasterio.open(image_path) as src:\n",
        "            image = src.read()\n",
        "        mask = Image.open(mask_path)\n",
        "\n",
        "        image = torch.tensor(image).permute(1,2,0).numpy()\n",
        "\n",
        "        mask = mask.resize(self.output_size)\n",
        "        mask_transform = transforms.Grayscale(1)\n",
        "        mask = mask_transform(mask)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35508b89",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-08T04:22:10.581537Z",
          "start_time": "2023-10-08T04:22:10.563536Z"
        },
        "id": "35508b89"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "# from dataset import PVDetectionDataset, image_transform, mask_transform\n",
        "from torch.utils.data import DataLoader\n",
        "# from sklearn.metrics import matthews_corrcoef, cohen_kappa_score\n",
        "import shutil\n",
        "\n",
        "\n",
        "\n",
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "    print(\"=> Loading Checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "\n",
        "def get_loaders(batch_size, train_ratio, val_ratio):\n",
        "    # Create a single dataset for all images in the folder\n",
        "    image_folder = \"images\"\n",
        "    masks_folder = \"masks\"\n",
        "    test_image_folder = \"test_images\"\n",
        "    test_masks_folder = \"test_masks\"\n",
        "\n",
        "    seed = 42\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # Create the custom dataset using all images and annotations\n",
        "    dataset = PVDetectionDataset(image_folder, masks_folder, transform=transform)\n",
        "    final_test_dataset = PVDetectionDataset(test_image_folder, test_masks_folder, transform=transform)\n",
        "\n",
        "    # Split the dataset into train, validation, and test sets if needed\n",
        "    # Example of splitting into train, val, and test (adjust the split ratios):\n",
        "    train_size = int(train_ratio * len(dataset))\n",
        "    val_size = int(val_ratio * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    # Create data loaders for training, validation, and testing\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    final_test_data_loader = torch.utils.data.DataLoader(final_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_data_loader, val_data_loader, test_data_loader, final_test_data_loader\n",
        "\n",
        "\n",
        "def validate_and_check_accuracy(loader, model, loss_fn, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()  # Apply threshold for binary prediction\n",
        "            val_loss = loss_fn(preds, y)\n",
        "            total_loss += val_loss.item()\n",
        "\n",
        "            num_correct += (preds == y).sum().item()\n",
        "            num_pixels += torch.numel(y)\n",
        "\n",
        "            # Calculate Dice score\n",
        "            intersection = (preds * y).sum().item()\n",
        "            union = preds.sum().item() + y.sum().item()\n",
        "            dice_score += (2 * intersection) / (union + 1e-8)\n",
        "\n",
        "    accuracy = (num_correct / num_pixels) * 100\n",
        "    dice_score /= len(loader)\n",
        "    average_loss = total_loss / len(loader)\n",
        "\n",
        "    print(f\"Got {num_correct}/{num_pixels} correct.\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Dice Score: {dice_score:.4f}\")\n",
        "    print(\"Validation Loss: {:.4f}\".format(average_loss))\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    return average_loss\n",
        "\n",
        "\n",
        "\n",
        "def save_predictions_as_imgs(loader, model, folder=\"saved_images/\", device=\"cuda\"):\n",
        "    model.eval()\n",
        "    if os.path.exists(folder):\n",
        "        shutil.rmtree(folder)  # Remove the folder and its contents\n",
        "    os.makedirs(folder, exist_ok=True)  # Recreate the output folder\n",
        "\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        x = x.to(device=device)\n",
        "        with torch.no_grad():\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()\n",
        "\n",
        "        # Save images\n",
        "        torchvision.utils.save_image(preds, f\"{folder}/pred_{idx}.png\")\n",
        "        torchvision.utils.save_image(y, f\"{folder}/{idx}.png\")\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "# Usage example:\n",
        "# save_predictions_as_imgs(loader, model, folder=\"output_folder\", device=\"cuda\")\n",
        "\n",
        "\n",
        "# Usage example:\n",
        "# save_predictions_as_imgs(loader, model, folder=\"output_folder\", device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def test_model(test_loader, model, device=\"cuda\"):\n",
        "    model.eval()  #\n",
        "    total_correct = 0\n",
        "    num_pixels = 0\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(test_loader, desc=\"Testing\"):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = torch.sigmoid(model(inputs))\n",
        "\n",
        "            # Calculate binary predictions (assuming a threshold of 0.5)\n",
        "            preds = (outputs > 0.5).float()\n",
        "            num_pixels += torch.numel(targets)\n",
        "\n",
        "            TP += ((preds == 1) & (targets == 1)).sum().item()\n",
        "            TN += ((preds == 0) & (targets == 0)).sum().item()\n",
        "            FP += ((preds == 1) & (targets == 0)).sum().item()\n",
        "            FN += ((preds == 0) & (targets == 1)).sum().item()\n",
        "\n",
        "            # You can also calculate Accuracy, Precision, Recall, and F1-score using these values:\n",
        "        accuracy = (TP + TN) / num_pixels\n",
        "        precision = TP / (TP + FP) if (TP + FP) != 0 else 0.0\n",
        "        recall = TP / (TP + FN) if (TP + FN) != 0 else 0.0\n",
        "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0.0\n",
        "        mcc = (TP * TN - FP * FN) / ((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))**0.5 if ((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) != 0 else 0.0\n",
        "\n",
        "            # Calculate Kappa Coefficient\n",
        "        total_agreement = (TP + TN) / num_pixels\n",
        "        expected_agreement = ((TP + FP) * (TP + FN) + (TN + FP) * (TN + FN)) / (num_pixels * num_pixels)\n",
        "        kappa = (total_agreement - expected_agreement) / (1 - expected_agreement) if (1 - expected_agreement) != 0 else 0.0\n",
        "\n",
        "\n",
        "            # Print or use these values as needed.\n",
        "        print(\"--------------------------------------\")\n",
        "        print(\"Evaluation Metrics\\n\")\n",
        "        print(f\"True Positives (TP): {TP}\")\n",
        "        print(f\"True Negatives (TN): {TN}\")\n",
        "        print(f\"False Positives (FP): {FP}\")\n",
        "        print(f\"False Negatives (FN): {FN}\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(f\"Precision: {precision}\")\n",
        "        print(f\"Recall: {recall}\")\n",
        "        print(f\"F1 Score: {f1_score}\")\n",
        "        print(f\"Matthews Correlation Coefficient (MCC): {mcc}\")\n",
        "        print(f\"Kappa Coefficient: {kappa}\")\n",
        "\n",
        "    # You can return the evaluation metrics as needed\n",
        "    return accuracy, precision, recall, f1_score, mcc, kappa"
      ],
      "metadata": {
        "id": "sDeIKKqhkqU7"
      },
      "id": "sDeIKKqhkqU7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d88d0230",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-08T04:23:05.816039Z",
          "start_time": "2023-10-08T04:22:10.582362Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d88d0230",
        "outputId": "36a5cb38-91e3-4a2b-81b8-3c2fe19a6719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.591]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7176\n",
            "Got 879966/5308416 correct.\n",
            "Accuracy: 16.58%\n",
            "Dice Score: 0.3006\n",
            "Validation Loss: 1.1360\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:20<00:00,  1.74s/it, loss=0.467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.5127\n",
            "Got 4312147/5308416 correct.\n",
            "Accuracy: 81.23%\n",
            "Dice Score: 0.0137\n",
            "Validation Loss: 0.6962\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.82s/it, loss=0.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4409\n",
            "Got 4526976/5308416 correct.\n",
            "Accuracy: 85.28%\n",
            "Dice Score: 0.4935\n",
            "Validation Loss: 0.6878\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.85s/it, loss=0.406]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4058\n",
            "Got 4681383/5308416 correct.\n",
            "Accuracy: 88.19%\n",
            "Dice Score: 0.7059\n",
            "Validation Loss: 0.6835\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.79s/it, loss=0.376]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3837\n",
            "Got 4886760/5308416 correct.\n",
            "Accuracy: 92.06%\n",
            "Dice Score: 0.8158\n",
            "Validation Loss: 0.6624\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.80s/it, loss=0.346]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3721\n",
            "Got 5096328/5308416 correct.\n",
            "Accuracy: 96.00%\n",
            "Dice Score: 0.9179\n",
            "Validation Loss: 0.6422\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.346]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3612\n",
            "Got 5083660/5308416 correct.\n",
            "Accuracy: 95.77%\n",
            "Dice Score: 0.9113\n",
            "Validation Loss: 0.6456\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.81s/it, loss=0.347]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3571\n",
            "Got 5004632/5308416 correct.\n",
            "Accuracy: 94.28%\n",
            "Dice Score: 0.8808\n",
            "Validation Loss: 0.6536\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.82s/it, loss=0.322]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3418\n",
            "Got 5138451/5308416 correct.\n",
            "Accuracy: 96.80%\n",
            "Dice Score: 0.9381\n",
            "Validation Loss: 0.6381\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.359]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3351\n",
            "Got 5135757/5308416 correct.\n",
            "Accuracy: 96.75%\n",
            "Dice Score: 0.9371\n",
            "Validation Loss: 0.6382\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.82s/it, loss=0.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3295\n",
            "Got 5135787/5308416 correct.\n",
            "Accuracy: 96.75%\n",
            "Dice Score: 0.9367\n",
            "Validation Loss: 0.6374\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.82s/it, loss=0.329]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3273\n",
            "Got 5134369/5308416 correct.\n",
            "Accuracy: 96.72%\n",
            "Dice Score: 0.9349\n",
            "Validation Loss: 0.6367\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.83s/it, loss=0.293]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3133\n",
            "Got 5131501/5308416 correct.\n",
            "Accuracy: 96.67%\n",
            "Dice Score: 0.9347\n",
            "Validation Loss: 0.6393\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.83s/it, loss=0.322]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3153\n",
            "Got 5148435/5308416 correct.\n",
            "Accuracy: 96.99%\n",
            "Dice Score: 0.9430\n",
            "Validation Loss: 0.6368\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.82s/it, loss=0.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3018\n",
            "Got 5112433/5308416 correct.\n",
            "Accuracy: 96.31%\n",
            "Dice Score: 0.9259\n",
            "Validation Loss: 0.6421\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-05.\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.286]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2915\n",
            "Got 5149310/5308416 correct.\n",
            "Accuracy: 97.00%\n",
            "Dice Score: 0.9438\n",
            "Validation Loss: 0.6372\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.83s/it, loss=0.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2869\n",
            "Got 5147426/5308416 correct.\n",
            "Accuracy: 96.97%\n",
            "Dice Score: 0.9429\n",
            "Validation Loss: 0.6375\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.83s/it, loss=0.293]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2855\n",
            "Got 5140583/5308416 correct.\n",
            "Accuracy: 96.84%\n",
            "Dice Score: 0.9400\n",
            "Validation Loss: 0.6382\n",
            "Epoch 00018: reducing learning rate of group 0 to 2.5000e-05.\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.85s/it, loss=0.269]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2782\n",
            "Got 5154505/5308416 correct.\n",
            "Accuracy: 97.10%\n",
            "Dice Score: 0.9467\n",
            "Validation Loss: 0.6365\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.82s/it, loss=0.283]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2808\n",
            "Got 5156832/5308416 correct.\n",
            "Accuracy: 97.14%\n",
            "Dice Score: 0.9479\n",
            "Validation Loss: 0.6362\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.83s/it, loss=0.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2758\n",
            "Got 5159040/5308416 correct.\n",
            "Accuracy: 97.19%\n",
            "Dice Score: 0.9492\n",
            "Validation Loss: 0.6357\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.402]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2814\n",
            "Got 5143696/5308416 correct.\n",
            "Accuracy: 96.90%\n",
            "Dice Score: 0.9412\n",
            "Validation Loss: 0.6382\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.82s/it, loss=0.268]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2766\n",
            "Got 5156223/5308416 correct.\n",
            "Accuracy: 97.13%\n",
            "Dice Score: 0.9476\n",
            "Validation Loss: 0.6358\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.86s/it, loss=0.265]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2727\n",
            "Got 5162275/5308416 correct.\n",
            "Accuracy: 97.25%\n",
            "Dice Score: 0.9506\n",
            "Validation Loss: 0.6351\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.289]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2707\n",
            "Got 5162442/5308416 correct.\n",
            "Accuracy: 97.25%\n",
            "Dice Score: 0.9510\n",
            "Validation Loss: 0.6354\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.81s/it, loss=0.262]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2684\n",
            "Got 5139792/5308416 correct.\n",
            "Accuracy: 96.82%\n",
            "Dice Score: 0.9392\n",
            "Validation Loss: 0.6390\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.292]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2668\n",
            "Got 5159763/5308416 correct.\n",
            "Accuracy: 97.20%\n",
            "Dice Score: 0.9498\n",
            "Validation Loss: 0.6359\n",
            "Epoch 00027: reducing learning rate of group 0 to 1.2500e-05.\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.83s/it, loss=0.258]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2633\n",
            "Got 5158529/5308416 correct.\n",
            "Accuracy: 97.18%\n",
            "Dice Score: 0.9491\n",
            "Validation Loss: 0.6361\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.86s/it, loss=0.278]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2620\n",
            "Got 5156171/5308416 correct.\n",
            "Accuracy: 97.13%\n",
            "Dice Score: 0.9479\n",
            "Validation Loss: 0.6365\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.303]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2627\n",
            "Got 5160549/5308416 correct.\n",
            "Accuracy: 97.21%\n",
            "Dice Score: 0.9503\n",
            "Validation Loss: 0.6359\n",
            "Epoch 00030: reducing learning rate of group 0 to 6.2500e-06.\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.83s/it, loss=0.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2620\n",
            "Got 5166775/5308416 correct.\n",
            "Accuracy: 97.33%\n",
            "Dice Score: 0.9533\n",
            "Validation Loss: 0.6347\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.85s/it, loss=0.259]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2582\n",
            "Got 5161666/5308416 correct.\n",
            "Accuracy: 97.24%\n",
            "Dice Score: 0.9509\n",
            "Validation Loss: 0.6357\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.82s/it, loss=0.242]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2588\n",
            "Got 5163750/5308416 correct.\n",
            "Accuracy: 97.27%\n",
            "Dice Score: 0.9519\n",
            "Validation Loss: 0.6353\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.85s/it, loss=0.265]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2584\n",
            "Got 5163975/5308416 correct.\n",
            "Accuracy: 97.28%\n",
            "Dice Score: 0.9521\n",
            "Validation Loss: 0.6354\n",
            "Epoch 00034: reducing learning rate of group 0 to 3.1250e-06.\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.253]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2586\n",
            "Got 5161302/5308416 correct.\n",
            "Accuracy: 97.23%\n",
            "Dice Score: 0.9508\n",
            "Validation Loss: 0.6359\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.265]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2572\n",
            "Got 5163952/5308416 correct.\n",
            "Accuracy: 97.28%\n",
            "Dice Score: 0.9521\n",
            "Validation Loss: 0.6354\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it, loss=0.257]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2571\n",
            "Got 5164636/5308416 correct.\n",
            "Accuracy: 97.29%\n",
            "Dice Score: 0.9524\n",
            "Validation Loss: 0.6353\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.5625e-06.\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.82s/it, loss=0.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2576\n",
            "Got 5163354/5308416 correct.\n",
            "Accuracy: 97.27%\n",
            "Dice Score: 0.9518\n",
            "Validation Loss: 0.6356\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.87s/it, loss=0.245]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2562\n",
            "Got 5163314/5308416 correct.\n",
            "Accuracy: 97.27%\n",
            "Dice Score: 0.9518\n",
            "Validation Loss: 0.6355\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.83s/it, loss=0.251]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2577\n",
            "Got 5164451/5308416 correct.\n",
            "Accuracy: 97.29%\n",
            "Dice Score: 0.9524\n",
            "Validation Loss: 0.6354\n",
            "Epoch 00040: reducing learning rate of group 0 to 7.8125e-07.\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:21<00:00,  1.83s/it, loss=0.258]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2570\n",
            "Got 5163894/5308416 correct.\n",
            "Accuracy: 97.28%\n",
            "Dice Score: 0.9521\n",
            "Validation Loss: 0.6355\n",
            "Validation loss has not improved for 10 epochs. Stopping early.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------\n",
            "Evaluation Metrics\n",
            "\n",
            "True Positives (TP): 715676\n",
            "True Negatives (TN): 4475528\n",
            "False Positives (FP): 29452\n",
            "False Negatives (FN): 18089\n",
            "Accuracy: 0.9779195903260031\n",
            "Precision: 0.9604739051545507\n",
            "Recall: 0.9753476930624928\n",
            "F1 Score: 0.9678536581077875\n",
            "Matthews Correlation Coefficient (MCC): 0.9626093853567806\n",
            "Kappa Coefficient: 0.915790983232865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# import albumentations as A\n",
        "# from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "# HYPERPARAMETERS\n",
        "LEARNING_RATE = 0.0001\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 100\n",
        "# NUM_WORKERS = 8\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH = 256\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "# PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "CLIP_VALUE = 5\n",
        "\n",
        "\n",
        "def train_fn(loader, model, optimizer, loss_fn):\n",
        "    loop = tqdm(loader)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.to(device=DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(data)\n",
        "        loss = loss_fn(predictions, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # update from tqdm\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    average_loss = total_loss / len(loader)\n",
        "    print(f\"Training Loss: {average_loss:.4f}\")\n",
        "\n",
        "\n",
        "model = UNET(in_channels=10, out_channels=1).to(DEVICE)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,  # Reduce LR by half when the metric plateaus\n",
        "    patience=2,  # Number of epochs with no improvement after which LR will be reduced\n",
        "    verbose=True,  # Print LR updates\n",
        "    min_lr=1e-8  # Minimum LR (optional)\n",
        ")\n",
        "\n",
        "# Define early stopping parameters\n",
        "early_stopping_patience = 10  # Number of epochs with no improvement after which to stop training\n",
        "best_val_loss = float('inf')  # Initialize with a large value\n",
        "\n",
        "train_loader, val_loader, test_loader = get_loaders(\n",
        "    BATCH_SIZE,\n",
        "    TRAIN_RATIO,\n",
        "    VAL_RATIO\n",
        ")\n",
        "\n",
        "if LOAD_MODEL:\n",
        "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_fn(train_loader, model, optimizer, loss_fn)\n",
        "\n",
        "    val_loss = validate_and_check_accuracy(val_loader, model, loss_fn, device=DEVICE)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Check for early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0  # Reset patience counter when there's improvement\n",
        "        best_model = model\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    # Early stopping check\n",
        "    if patience_counter >= early_stopping_patience:\n",
        "        print(f\"Validation loss has not improved for {early_stopping_patience} epochs. Stopping early.\")\n",
        "        break\n",
        "\n",
        "    # save model\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "\n",
        "\n",
        "    save_checkpoint(checkpoint)\n",
        "\n",
        "    # print some examples to a folder\n",
        "    save_predictions_as_imgs(\n",
        "        val_loader, best_model, folder=\"saved_images\", device=DEVICE\n",
        "    )\n",
        "\n",
        "save_predictions_as_imgs(\n",
        "    test_loader, best_model, folder=\"test_images\", device=DEVICE\n",
        ")\n",
        "\n",
        "save_predictions_as_imgs(\n",
        "    final_test_loader, best_model, folder=\"final_test_images\", device=DEVICE\n",
        ")\n",
        "\n",
        "\n",
        "test_accuracy, precision, recall, f1_score, mcc, kappa = test_model(test_loader, best_model, device=\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed356dd",
      "metadata": {
        "id": "eed356dd"
      },
      "source": [
        "### CHANGES MADE:\n",
        "\n",
        "1) Added grad_norm_ for clipping gradients\n",
        "\n",
        "2) Removed Scaler."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from tqdm import tqdm\n",
        "# import torch.nn as nn\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, cohen_kappa_score\n",
        "\n",
        "# def test_model(test_loader, model, device=\"cuda\"):\n",
        "#     model.eval()  # Set the model to evaluation mode\n",
        "#     total_correct = 0\n",
        "#     total_samples = 0\n",
        "#     criterion = nn.BCEWithLogitsLoss()  # You can change this loss function as needed\n",
        "\n",
        "#     true_labels = []\n",
        "#     predicted_labels = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, targets in tqdm(test_loader, desc=\"Testing\"):\n",
        "#             inputs = inputs.to(device)\n",
        "#             targets = targets.to(device)\n",
        "\n",
        "#             # Forward pass\n",
        "#             outputs = model(inputs)\n",
        "\n",
        "#             # Compute loss (if needed)\n",
        "#             loss = criterion(outputs, targets)\n",
        "\n",
        "#             # Calculate binary predictions (assuming a threshold of 0.5)\n",
        "#             predicted = (outputs > 0.5).float()\n",
        "\n",
        "#             # Update lists for evaluation metrics\n",
        "#             true_labels.extend(targets.cpu().numpy())\n",
        "#             predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "#             total_samples += targets.size(0)\n",
        "#             total_correct += (predicted == targets).sum().item()\n",
        "\n",
        "#     # Calculate accuracy\n",
        "#     accuracy = 100.0 * total_correct / total_samples\n",
        "#     print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "#     # Calculate other evaluation metrics\n",
        "#     precision = precision_score(true_labels, predicted_labels)\n",
        "#     recall = recall_score(true_labels, predicted_labels)\n",
        "#     f1 = f1_score(true_labels, predicted_labels)\n",
        "#     mcc = matthews_corrcoef(true_labels, predicted_labels)\n",
        "#     kappa = cohen_kappa_score(true_labels, predicted_labels)\n",
        "\n",
        "#     print(f\"Precision: {precision:.4f}\")\n",
        "#     print(f\"Recall: {recall:.4f}\")\n",
        "#     print(f\"F1-Score: {f1:.4f}\")\n",
        "#     print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
        "#     print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
        "\n",
        "#     # You can return the evaluation metrics as needed\n",
        "#     return accuracy, precision, recall, f1, mcc, kappa\n",
        "\n",
        "# # Usage:\n",
        "# # Call the test_model function with your test data loader and trained model\n",
        "# # test_accuracy, precision, recall, f1_score, mcc, kappa = test_model(test_loader, model, device=\"cuda\")"
      ],
      "metadata": {
        "id": "OQIOaWZOHZdx"
      },
      "id": "OQIOaWZOHZdx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ed1564a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-08T04:23:05.818889Z",
          "start_time": "2023-10-08T04:23:05.818889Z"
        },
        "id": "7ed1564a"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0b03c44",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-08T04:23:05.820465Z",
          "start_time": "2023-10-08T04:23:05.820465Z"
        },
        "id": "c0b03c44"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader, val_loader, test_loader = get_loaders(\n",
        "#         DATA_DIR,\n",
        "#         BATCH_SIZE,\n",
        "#         TRAIN_RATIO,\n",
        "#         VAL_RATIO\n",
        "# #         NUM_WORKERS,\n",
        "# #         PIN_MEMORY,\n",
        "#     )"
      ],
      "metadata": {
        "id": "3NxZy4gq16Sq"
      },
      "id": "3NxZy4gq16Sq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iwB5_JDI631e"
      },
      "id": "iwB5_JDI631e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb5740de",
      "metadata": {
        "id": "cb5740de"
      },
      "outputs": [],
      "source": [
        "# for x, y in train_loader:\n",
        "#     print(\"Input shape:\", x.shape)\n",
        "#     print(\"Label shape:\", y.shape)\n",
        "#     break  # Print only the first batch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset"
      ],
      "metadata": {
        "id": "QOMgwGx01Rh2"
      },
      "id": "QOMgwGx01Rh2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install rasterio"
      ],
      "metadata": {
        "id": "QxeFg2Lx31Ss"
      },
      "id": "QxeFg2Lx31Ss",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "63nywQxQMXEB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cd26a275-36af-4d39-8347-f2dc75b3d853"
      },
      "id": "63nywQxQMXEB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SVLJzOYxQFvd"
      },
      "id": "SVLJzOYxQFvd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}